{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aD0UzBIX17JX"
      },
      "source": [
        "# Building our own Face Detection model\n",
        "\n",
        "This model comes with..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwKoZ0ocZmIn"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZJdox8nPbugJ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thierryksstentini/opt/miniforge3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import glob\n",
        "import pickle\n",
        "import tqdm\n",
        "import random as rd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchinfo import summary\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms\n",
        "\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0L1DXFKxpc2S"
      },
      "outputs": [],
      "source": [
        "class FaceDetection_dataset(Dataset):\n",
        "    def __init__(self, imgset_face:list, imgset_noface:list, val_stride:int=0, isValSet_bool:bool=False, \n",
        "                 isAugment_bool:bool=False, isNormalize_bool:bool=False):\n",
        "        \"\"\"\n",
        "        Class that build the dataset to feed the Pytorch Dataloader \n",
        "\n",
        "        -------------------\n",
        "        Class attributs:\n",
        "            imgset_face: list of PIL images\n",
        "                The list of PIL images with face in it\n",
        "            imgset_face: list of PIL images.\n",
        "                The list of PIL images without face in it (typically random\n",
        "                background found in the 'houseroom dataset').\n",
        "            val_stride: int\n",
        "                Use to select training images and validation images without data\n",
        "                leaks.\n",
        "            isValSet_bool: bool\n",
        "                Boolean to construct a validation dataset\n",
        "            isAugment_bool: bool\n",
        "                Boolean to activate the data augmentation preprocessing\n",
        "            isNormalize_bool: bool\n",
        "                Boolean to activate normalization of each image by its own mean\n",
        "                and std values.\n",
        "        \"\"\"\n",
        "        \n",
        "        self.isAugment_bool = isAugment_bool\n",
        "        self.isNormalize_bool = isNormalize_bool\n",
        "        \n",
        "        self.imgset = imgset_face + imgset_noface        \n",
        "        \n",
        "        label_face = np.ones(len(imgset_face)).tolist()\n",
        "        label_noface = np.zeros(len(imgset_noface)).tolist()\n",
        "        self.labelset = label_face + label_noface\n",
        "        \n",
        "        if isValSet_bool:\n",
        "            assert val_stride > 0, 'val_stride should be greater than zero'\n",
        "            self.imgset = self.imgset[::val_stride]\n",
        "            self.labelset = self.labelset[::val_stride]\n",
        "       \n",
        "        elif val_stride > 0:\n",
        "            del self.imgset[::val_stride]\n",
        "            del self.labelset[::val_stride]\n",
        "\n",
        "    def preprocess(self, img)->torch.Tensor:\n",
        "        transform = torchvision.transforms.Compose(\n",
        "            [torchvision.transforms.Resize((256)), \n",
        "                torchvision.transforms.ToTensor(),\n",
        "                torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "        img_t = transform(img)\n",
        "        \n",
        "        if self.isAugment_bool:\n",
        "            \"\"\" to do \"\"\"\n",
        "            augment = torchvision.transforms.Compose([\n",
        "                torchvision.transforms.CenterCrop(224),\n",
        "                torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
        "                torchvision.transforms.RandomRotation(degrees=(-10,10))\n",
        "            ])\n",
        "            img_t = augment(img_t)\n",
        "        \n",
        "\n",
        "        if self.isNormalize_bool:\n",
        "            mean, std = img_t.mean(), img_t.std()\n",
        "            img_t = (img_t - mean) / std\n",
        "\n",
        "        return img_t\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgset)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        image = self.imgset[idx]\n",
        "        image = self.preprocess(image)\n",
        "        \n",
        "        label = self.labelset[idx]\n",
        "            \n",
        "        return image, torch.tensor(label).to(torch.float32)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNVduGWRcVPR"
      },
      "source": [
        "# Loading data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Working in the CLOUD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### https://www.kaggle.com/datasets/robinreni/house-rooms-image-dataset\n",
        "### http://vis-www.cs.umass.edu/lfw/\n",
        "\n",
        "data_path = '/content/drive/MyDrive/Colab Notebooks'\n",
        "\n",
        "#----------------------------- Loading images with a face ---------------------#\n",
        "#imgset_face_path = glob.glob(data_path + '/face_verification/*dataset/*lfw/*/*')\n",
        "#imgset_face_PIL = [Image.open(k).convert('RGB') for k in imgset_face_path]\n",
        "with open(data_path + '/face_verification/dataset/dataset_augmented/lfw_PIL.pkl', 'rb') as lfw_PIL:\n",
        "    imgset_face_PIL = pickle.load(lfw_PIL)\n",
        "\n",
        "\n",
        "#----------------------------- Loading images without face --------------------#\n",
        "#imgset_noface_path = glob.glob(data_path + '/face_verification/*dataset/*houseroom/*/*')\n",
        "#imgset_noface_PIL = [Image.open(k).convert('RGB') for k in imgset_noface_path]\n",
        "with open(data_path + '/face_verification/dataset/houseroom/houseroom_3000_PIL.pkl', 'rb') as houseroom_PIL:\n",
        "    imgset_noface_PIL = pickle.load(houseroom_PIL)### https://www.kaggle.com/datasets/robinreni/house-rooms-image-dataset\n",
        "### http://vis-www.cs.umass.edu/lfw/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Working in LOCAL MACHINE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_path = '/Users/thierryksstentini/Downloads/dataset'\n",
        "\n",
        "#----------------------------- Loading images with a face ---------------------#\n",
        "with open(data_path + '/dataset_augmented/lfw_PIL.pkl', 'rb') as lfw_PIL:\n",
        "    imgset_face_PIL = pickle.load(lfw_PIL)\n",
        "\n",
        "\n",
        "#----------------------------- Loading images without face --------------------#\n",
        "with open(data_path + '/houseroom_3000_PIL.pkl', 'rb') as houseroom_PIL:\n",
        "    imgset_noface_PIL = pickle.load(houseroom_PIL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "J_4D2oPbo2k8"
      },
      "outputs": [],
      "source": [
        "#----------------------------- Creating datasets ------------------------------#\n",
        "dataset_train = FaceDetection_dataset(imgset_face_PIL, imgset_noface_PIL, val_stride=10, isValSet_bool=False, isAugment_bool=True)\n",
        "dataset_val = FaceDetection_dataset(imgset_face_PIL, imgset_noface_PIL, val_stride=10, isValSet_bool=True)\n",
        "\n",
        "del imgset_face_PIL, imgset_noface_PIL\n",
        "\n",
        "#----------------------------- Creating loaders -------------------------------#\n",
        "BATCH_SIZE = 64\n",
        "train_dataloader = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_dataloader = DataLoader(dataset_val, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfVzyPJKcY50"
      },
      "source": [
        "# Creating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class resNet50_custom(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(resNet50_custom, self).__init__()\n",
        "        self.res50 = torchvision.models.resnet50(pretrained = True, progress = True)\n",
        "        for param in self.res50.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.res50.fc = nn.Linear(2048, 1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.res50(input)\n",
        "        return torch.sigmoid(output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thierryksstentini/opt/miniforge3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/Users/thierryksstentini/opt/miniforge3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "#device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "resNet50_model = resNet50_custom()\n",
        "optimizer = torch.optim.Adam(resNet50_model.parameters(), lr=0.001)\n",
        "num_epochs = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thierryksstentini/opt/miniforge3/lib/python3.9/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "===============================================================================================\n",
              "Layer (type:depth-idx)                        Output Shape              Param #\n",
              "===============================================================================================\n",
              "resNet50_custom                               [32, 1]                   --\n",
              "├─ResNet: 1-1                                 [32, 1]                   --\n",
              "│    └─Conv2d: 2-1                            [32, 64, 112, 112]        (9,408)\n",
              "│    └─BatchNorm2d: 2-2                       [32, 64, 112, 112]        (128)\n",
              "│    └─ReLU: 2-3                              [32, 64, 112, 112]        --\n",
              "│    └─MaxPool2d: 2-4                         [32, 64, 56, 56]          --\n",
              "│    └─Sequential: 2-5                        [32, 256, 56, 56]         --\n",
              "│    │    └─Bottleneck: 3-1                   [32, 256, 56, 56]         (75,008)\n",
              "│    │    └─Bottleneck: 3-2                   [32, 256, 56, 56]         (70,400)\n",
              "│    │    └─Bottleneck: 3-3                   [32, 256, 56, 56]         (70,400)\n",
              "│    └─Sequential: 2-6                        [32, 512, 28, 28]         --\n",
              "│    │    └─Bottleneck: 3-4                   [32, 512, 28, 28]         (379,392)\n",
              "│    │    └─Bottleneck: 3-5                   [32, 512, 28, 28]         (280,064)\n",
              "│    │    └─Bottleneck: 3-6                   [32, 512, 28, 28]         (280,064)\n",
              "│    │    └─Bottleneck: 3-7                   [32, 512, 28, 28]         (280,064)\n",
              "│    └─Sequential: 2-7                        [32, 1024, 14, 14]        --\n",
              "│    │    └─Bottleneck: 3-8                   [32, 1024, 14, 14]        (1,512,448)\n",
              "│    │    └─Bottleneck: 3-9                   [32, 1024, 14, 14]        (1,117,184)\n",
              "│    │    └─Bottleneck: 3-10                  [32, 1024, 14, 14]        (1,117,184)\n",
              "│    │    └─Bottleneck: 3-11                  [32, 1024, 14, 14]        (1,117,184)\n",
              "│    │    └─Bottleneck: 3-12                  [32, 1024, 14, 14]        (1,117,184)\n",
              "│    │    └─Bottleneck: 3-13                  [32, 1024, 14, 14]        (1,117,184)\n",
              "│    └─Sequential: 2-8                        [32, 2048, 7, 7]          --\n",
              "│    │    └─Bottleneck: 3-14                  [32, 2048, 7, 7]          (6,039,552)\n",
              "│    │    └─Bottleneck: 3-15                  [32, 2048, 7, 7]          (4,462,592)\n",
              "│    │    └─Bottleneck: 3-16                  [32, 2048, 7, 7]          (4,462,592)\n",
              "│    └─AdaptiveAvgPool2d: 2-9                 [32, 2048, 1, 1]          --\n",
              "│    └─Linear: 2-10                           [32, 1]                   2,049\n",
              "===============================================================================================\n",
              "Total params: 23,510,081\n",
              "Trainable params: 2,049\n",
              "Non-trainable params: 23,508,032\n",
              "Total mult-adds (G): 130.79\n",
              "===============================================================================================\n",
              "Input size (MB): 19.27\n",
              "Forward/backward pass size (MB): 5690.36\n",
              "Params size (MB): 94.04\n",
              "Estimated Total Size (MB): 5803.67\n",
              "==============================================================================================="
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary(resNet50_model, (32, 3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "------------------------------------\n",
            "Execute notebook on - mps -\n",
            "------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### Choosing device between CPU or GPU\n",
        "#device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "device = torch.device('mps') if torch.has_mps else torch.device('cpu')\n",
        "print(\"\\n------------------------------------\")\n",
        "print(f\"Execute notebook on - {device} -\")\n",
        "print(\"------------------------------------\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "32e2a52a05e24d60b7548433155e72ae",
            "505db89d72b34a34971291ccfaf0b3ff",
            "4c553a6a3c224c07b42016e31ac7285d",
            "c58a474359344e4e9944c2115121cf7d",
            "4f205a6e23cd4a12947ea64ef1dc986e",
            "fa83ab9de4374921853df19db53dded8",
            "439e24adee154320b79b7cac83c53a30",
            "ac34c26b2cdf4c1493da71ed7e5410f0",
            "2c7a8660130e40bbab6de68e755ca128",
            "0fc7e5f1d6274e0da948779e948627e3",
            "c913ab7aad7e49a79fde819c99acd1a4"
          ]
        },
        "id": "N5PcQVGJuuKn",
        "outputId": "0b820240-8840-4c40-c9aa-903927a148a6"
      },
      "outputs": [],
      "source": [
        "######## OLD ###############\n",
        "#res50 = torchvision.models.resnet50(pretrained = True, progress = True)\n",
        "\n",
        "### Freezing all weights\n",
        "#for param in res50.parameters():\n",
        "#  param.requires_grad = False\n",
        "\n",
        "### Turning the last fc layer such that it has 2 outputs\n",
        "#res50.fc = nn.Linear(2048, 2)\n",
        "\n",
        "\n",
        "#optimizer = torch.optim.SGD(res50.parameters(), lr=0.01)\n",
        "#num_epochs = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5JlRfaDcfOV"
      },
      "source": [
        "# Building the training loop function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UMXZknaVuWer"
      },
      "outputs": [],
      "source": [
        "def model_loop(model, epochs, trainloader, validloader, optimizer, loss_fn, device):\n",
        "    model.to(device)\n",
        "    train_loss_list = []\n",
        "    valid_loss_list = []\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"Epoch {epoch+1} on {device} \\n-------------------------------\")\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        size = len(trainloader.dataset)\n",
        "        \n",
        "        for batch, (data, labels) in enumerate(trainloader):\n",
        "            # Transfer Data to GPU if available\n",
        "            data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "            # Clear the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Make prediction & compute the mini-batch training loss\n",
        "            preds = model(data)\n",
        "            loss = loss_fn(preds, labels.unsqueeze(1))\n",
        "\n",
        "            # Compute the gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Update Weights\n",
        "            optimizer.step()\n",
        "\n",
        "            # Aggregate mini-batch training losses\n",
        "            train_loss += loss.item()\n",
        "            train_loss_list.append(train_loss)\n",
        "\n",
        "            \n",
        "            if (batch) == 0 or (batch) % 10 == 0:\n",
        "                loss, current = loss.item(), (batch+1) * len(data)\n",
        "                print(f\"mini-batch loss for training : {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "        \n",
        "        # Compute the global training loss as the mean of the mini-batch training losses\n",
        "        train_loss /= len(trainloader)\n",
        "      \n",
        "        model.eval()\n",
        "        valid_loss = 0.0\n",
        "        # Test part : no gradient update\n",
        "        with torch.no_grad():\n",
        "            for batch, (data, labels) in enumerate(validloader):\n",
        "                # Transfer Data to GPU if available\n",
        "                data, labels = data.to(device), labels.to(device)\n",
        "                # Forward Pass & compute the mini-batch validation loss\n",
        "                preds = model(data)\n",
        "                loss = loss_fn(preds,labels.unsqueeze(1))\n",
        "\n",
        "                # Calculate Loss\n",
        "                valid_loss += loss.item()\n",
        "                valid_loss_list.append(valid_loss)\n",
        "\n",
        "                if (batch)==1 or batch % 10 == 0:\n",
        "                    loss, current = loss.item(), (batch+1) * len(data)\n",
        "                    print(f\"mini-batch loss for validation : {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "        \n",
        "        # Compute the global validation loss as the mean of the mini-batch validation losses\n",
        "        valid_loss /= len(validloader)\n",
        "\n",
        "        print(f\"Epoch {epoch+1} \\n Training Loss: {train_loss:>7f} \\n Validation Loss: {valid_loss:>7f}\" )\n",
        "\n",
        "    return train_loss_list, valid_loss_list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFfMqBzKcldY"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tECr8i3nuoGM",
        "outputId": "82cd1475-32f4-459f-a4be-9452c773b61e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 on mps \n",
            "-------------------------------\n",
            "mini-batch loss for training : 0.720107  [   64/ 5536]\n",
            "mini-batch loss for training : 0.352562  [  704/ 5536]\n",
            "mini-batch loss for training : 0.156644  [ 1344/ 5536]\n",
            "mini-batch loss for training : 0.092138  [ 1984/ 5536]\n",
            "mini-batch loss for training : 0.061273  [ 2624/ 5536]\n",
            "mini-batch loss for training : 0.050467  [ 3264/ 5536]\n",
            "mini-batch loss for training : 0.037645  [ 3904/ 5536]\n",
            "mini-batch loss for training : 0.029562  [ 4544/ 5536]\n",
            "mini-batch loss for training : 0.022191  [ 5184/ 5536]\n",
            "mini-batch loss for validation : 0.026554  [   64/ 5536]\n",
            "mini-batch loss for validation : 0.034488  [  128/ 5536]\n",
            "Epoch 1 \n",
            " Training Loss: 0.139392 \n",
            " Validation Loss: 0.035579\n",
            "Epoch 2 on mps \n",
            "-------------------------------\n",
            "mini-batch loss for training : 0.026168  [   64/ 5536]\n",
            "mini-batch loss for training : 0.020003  [  704/ 5536]\n",
            "mini-batch loss for training : 0.023405  [ 1344/ 5536]\n",
            "mini-batch loss for training : 0.015105  [ 1984/ 5536]\n",
            "mini-batch loss for training : 0.017134  [ 2624/ 5536]\n",
            "mini-batch loss for training : 0.012294  [ 3264/ 5536]\n",
            "mini-batch loss for training : 0.036547  [ 3904/ 5536]\n",
            "mini-batch loss for training : 0.053371  [ 4544/ 5536]\n",
            "mini-batch loss for training : 0.014118  [ 5184/ 5536]\n",
            "mini-batch loss for validation : 0.013930  [   64/ 5536]\n",
            "mini-batch loss for validation : 0.020526  [  128/ 5536]\n",
            "Epoch 2 \n",
            " Training Loss: 0.020642 \n",
            " Validation Loss: 0.017524\n",
            "Epoch 3 on mps \n",
            "-------------------------------\n",
            "mini-batch loss for training : 0.012426  [   64/ 5536]\n",
            "mini-batch loss for training : 0.010597  [  704/ 5536]\n",
            "mini-batch loss for training : 0.009027  [ 1344/ 5536]\n",
            "mini-batch loss for training : 0.009919  [ 1984/ 5536]\n",
            "mini-batch loss for training : 0.033157  [ 2624/ 5536]\n",
            "mini-batch loss for training : 0.007520  [ 3264/ 5536]\n",
            "mini-batch loss for training : 0.039504  [ 3904/ 5536]\n",
            "mini-batch loss for training : 0.018246  [ 4544/ 5536]\n",
            "mini-batch loss for training : 0.021186  [ 5184/ 5536]\n",
            "mini-batch loss for validation : 0.005834  [   64/ 5536]\n",
            "mini-batch loss for validation : 0.010025  [  128/ 5536]\n",
            "Epoch 3 \n",
            " Training Loss: 0.011904 \n",
            " Validation Loss: 0.012350\n",
            "Epoch 4 on mps \n",
            "-------------------------------\n",
            "mini-batch loss for training : 0.022560  [   64/ 5536]\n",
            "mini-batch loss for training : 0.004493  [  704/ 5536]\n",
            "mini-batch loss for training : 0.005498  [ 1344/ 5536]\n",
            "mini-batch loss for training : 0.005852  [ 1984/ 5536]\n",
            "mini-batch loss for training : 0.026757  [ 2624/ 5536]\n",
            "mini-batch loss for training : 0.013849  [ 3264/ 5536]\n",
            "mini-batch loss for training : 0.004131  [ 3904/ 5536]\n",
            "mini-batch loss for training : 0.003890  [ 4544/ 5536]\n",
            "mini-batch loss for training : 0.006464  [ 5184/ 5536]\n",
            "mini-batch loss for validation : 0.007227  [   64/ 5536]\n",
            "mini-batch loss for validation : 0.012604  [  128/ 5536]\n",
            "Epoch 4 \n",
            " Training Loss: 0.007458 \n",
            " Validation Loss: 0.007950\n",
            "Epoch 5 on mps \n",
            "-------------------------------\n",
            "mini-batch loss for training : 0.005695  [   64/ 5536]\n",
            "mini-batch loss for training : 0.010677  [  704/ 5536]\n",
            "mini-batch loss for training : 0.004098  [ 1344/ 5536]\n",
            "mini-batch loss for training : 0.006318  [ 1984/ 5536]\n",
            "mini-batch loss for training : 0.005813  [ 2624/ 5536]\n",
            "mini-batch loss for training : 0.003168  [ 3264/ 5536]\n",
            "mini-batch loss for training : 0.003082  [ 3904/ 5536]\n",
            "mini-batch loss for training : 0.002945  [ 4544/ 5536]\n",
            "mini-batch loss for training : 0.002370  [ 5184/ 5536]\n",
            "mini-batch loss for validation : 0.005479  [   64/ 5536]\n",
            "mini-batch loss for validation : 0.010819  [  128/ 5536]\n",
            "Epoch 5 \n",
            " Training Loss: 0.005045 \n",
            " Validation Loss: 0.006352\n"
          ]
        }
      ],
      "source": [
        "loss = nn.BCELoss()\n",
        "train_loss, valid_loss = model_loop(model = resNet50_model,\n",
        "                                    epochs = num_epochs,\n",
        "                                    trainloader = train_dataloader,\n",
        "                                    validloader = val_dataloader,\n",
        "                                    optimizer = optimizer,\n",
        "                                    loss_fn = loss,\n",
        "                                    device = device) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5IQX8l2RC-4"
      },
      "outputs": [],
      "source": [
        "losses = {'train_loss' : train_loss, 'valid_loss' : valid_loss}\n",
        "import pickle\n",
        "with open(\"losses.pickle\", \"wb\") as file:\n",
        "    pickle.dump(losses, file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "lpTlf-xIu8WF"
      },
      "outputs": [],
      "source": [
        "def test_accuracy(model, validloader, device):\n",
        "    correct_results_sum = 0\n",
        "    total = len(validloader.dataset)\n",
        "    model.eval()\n",
        "\n",
        "    # test part : no gradient update\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in validloader :\n",
        "            # Transfer Data to GPU if available\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "            # Prediction on unseen data as 0 or 1\n",
        "            outputs = model(imgs)\n",
        "            predicted = torch.round(outputs).squeeze(1)\n",
        "            # print(predicted.shape, labels.shape)\n",
        "            # print((predicted == labels).shape)\n",
        "\n",
        "            # Aggregate and sum the correct predictions for each mini-batch\n",
        "            correct_results_sum += (predicted == labels).sum().float()\n",
        "\n",
        "    # Mean of the mini-batch correct predictions\n",
        "    acc = correct_results_sum / total\n",
        "    acc = torch.round(acc * 100)\n",
        "    print(\"Validation accuracy : {:.2f}\".format(acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "iZ4-d1M8vUnZ",
        "outputId": "5405f650-3a3c-4afd-bda8-b27b69b67a2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy : 100.00\n"
          ]
        }
      ],
      "source": [
        "test_accuracy(resNet50_model, val_dataloader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-D0MiAP1UKr",
        "outputId": "8dd84346-a82e-40f3-820a-edfe3fff8118"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "347"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "img_de_moi = glob.glob('/Users/thierryksstentini/Downloads/dataset/dataset_sven/dataset_moi_sven_cropped/*')\n",
        "len(img_de_moi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uy8LUWv0aBRU",
        "outputId": "7f454e55-f44d-47a0-e7af-aca5fbc87522"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thierryksstentini/opt/miniforge3/lib/python3.9/site-packages/torch/_tensor_str.py:107: UserWarning: The operator 'aten::bitwise_and.Tensor_out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
            "  tensor_view, torch.isfinite(tensor_view) & tensor_view.ne(0)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[tensor([[0.9885]], device='mps:0'),\n",
              " tensor([[0.9889]], device='mps:0'),\n",
              " tensor([[0.9767]], device='mps:0'),\n",
              " tensor([[0.9949]], device='mps:0'),\n",
              " tensor([[0.9989]], device='mps:0'),\n",
              " tensor([[0.9725]], device='mps:0'),\n",
              " tensor([[0.9840]], device='mps:0'),\n",
              " tensor([[0.9911]], device='mps:0'),\n",
              " tensor([[0.9954]], device='mps:0'),\n",
              " tensor([[0.9447]], device='mps:0'),\n",
              " tensor([[0.9100]], device='mps:0'),\n",
              " tensor([[0.9983]], device='mps:0'),\n",
              " tensor([[0.9978]], device='mps:0'),\n",
              " tensor([[0.9728]], device='mps:0'),\n",
              " tensor([[0.9859]], device='mps:0'),\n",
              " tensor([[0.9971]], device='mps:0'),\n",
              " tensor([[0.9814]], device='mps:0'),\n",
              " tensor([[0.9702]], device='mps:0'),\n",
              " tensor([[0.9924]], device='mps:0'),\n",
              " tensor([[0.9964]], device='mps:0'),\n",
              " tensor([[0.9978]], device='mps:0'),\n",
              " tensor([[0.9713]], device='mps:0'),\n",
              " tensor([[0.9884]], device='mps:0'),\n",
              " tensor([[0.9782]], device='mps:0'),\n",
              " tensor([[0.9615]], device='mps:0'),\n",
              " tensor([[0.9692]], device='mps:0'),\n",
              " tensor([[0.9918]], device='mps:0'),\n",
              " tensor([[0.9856]], device='mps:0'),\n",
              " tensor([[0.9161]], device='mps:0'),\n",
              " tensor([[0.9686]], device='mps:0'),\n",
              " tensor([[0.9930]], device='mps:0'),\n",
              " tensor([[0.9965]], device='mps:0'),\n",
              " tensor([[0.9906]], device='mps:0'),\n",
              " tensor([[0.9818]], device='mps:0'),\n",
              " tensor([[0.9899]], device='mps:0'),\n",
              " tensor([[0.9592]], device='mps:0'),\n",
              " tensor([[0.9503]], device='mps:0'),\n",
              " tensor([[0.9500]], device='mps:0'),\n",
              " tensor([[0.9605]], device='mps:0'),\n",
              " tensor([[0.9483]], device='mps:0'),\n",
              " tensor([[0.9892]], device='mps:0'),\n",
              " tensor([[0.9824]], device='mps:0'),\n",
              " tensor([[0.9485]], device='mps:0'),\n",
              " tensor([[0.9887]], device='mps:0'),\n",
              " tensor([[0.9864]], device='mps:0'),\n",
              " tensor([[0.9700]], device='mps:0'),\n",
              " tensor([[0.9779]], device='mps:0'),\n",
              " tensor([[0.9831]], device='mps:0'),\n",
              " tensor([[0.9844]], device='mps:0'),\n",
              " tensor([[0.9920]], device='mps:0'),\n",
              " tensor([[0.9318]], device='mps:0'),\n",
              " tensor([[0.9949]], device='mps:0'),\n",
              " tensor([[0.9903]], device='mps:0'),\n",
              " tensor([[0.9575]], device='mps:0'),\n",
              " tensor([[0.9522]], device='mps:0'),\n",
              " tensor([[0.9581]], device='mps:0'),\n",
              " tensor([[0.9520]], device='mps:0'),\n",
              " tensor([[0.9945]], device='mps:0'),\n",
              " tensor([[0.9982]], device='mps:0'),\n",
              " tensor([[0.9865]], device='mps:0'),\n",
              " tensor([[0.9235]], device='mps:0'),\n",
              " tensor([[0.9880]], device='mps:0'),\n",
              " tensor([[0.9823]], device='mps:0'),\n",
              " tensor([[0.9616]], device='mps:0'),\n",
              " tensor([[0.9514]], device='mps:0'),\n",
              " tensor([[0.8880]], device='mps:0'),\n",
              " tensor([[0.9650]], device='mps:0'),\n",
              " tensor([[0.9527]], device='mps:0'),\n",
              " tensor([[0.9659]], device='mps:0'),\n",
              " tensor([[0.9874]], device='mps:0'),\n",
              " tensor([[0.9906]], device='mps:0'),\n",
              " tensor([[0.9927]], device='mps:0'),\n",
              " tensor([[0.9611]], device='mps:0'),\n",
              " tensor([[0.9566]], device='mps:0'),\n",
              " tensor([[0.9677]], device='mps:0'),\n",
              " tensor([[0.9967]], device='mps:0'),\n",
              " tensor([[0.9918]], device='mps:0'),\n",
              " tensor([[0.9458]], device='mps:0'),\n",
              " tensor([[0.9898]], device='mps:0'),\n",
              " tensor([[0.9921]], device='mps:0'),\n",
              " tensor([[0.9679]], device='mps:0'),\n",
              " tensor([[0.9786]], device='mps:0'),\n",
              " tensor([[0.9845]], device='mps:0'),\n",
              " tensor([[0.9758]], device='mps:0'),\n",
              " tensor([[0.9896]], device='mps:0'),\n",
              " tensor([[0.9938]], device='mps:0'),\n",
              " tensor([[0.9945]], device='mps:0'),\n",
              " tensor([[0.9297]], device='mps:0'),\n",
              " tensor([[0.9804]], device='mps:0'),\n",
              " tensor([[0.9690]], device='mps:0'),\n",
              " tensor([[0.8930]], device='mps:0'),\n",
              " tensor([[0.9915]], device='mps:0'),\n",
              " tensor([[0.9652]], device='mps:0'),\n",
              " tensor([[0.9631]], device='mps:0'),\n",
              " tensor([[0.9942]], device='mps:0'),\n",
              " tensor([[0.9920]], device='mps:0'),\n",
              " tensor([[0.9917]], device='mps:0'),\n",
              " tensor([[0.9957]], device='mps:0'),\n",
              " tensor([[0.9836]], device='mps:0'),\n",
              " tensor([[0.9874]], device='mps:0'),\n",
              " tensor([[0.9960]], device='mps:0'),\n",
              " tensor([[0.9659]], device='mps:0'),\n",
              " tensor([[0.9659]], device='mps:0'),\n",
              " tensor([[0.9554]], device='mps:0'),\n",
              " tensor([[0.9770]], device='mps:0'),\n",
              " tensor([[0.8626]], device='mps:0'),\n",
              " tensor([[0.9047]], device='mps:0'),\n",
              " tensor([[0.9744]], device='mps:0'),\n",
              " tensor([[0.9813]], device='mps:0'),\n",
              " tensor([[0.9970]], device='mps:0'),\n",
              " tensor([[0.9947]], device='mps:0'),\n",
              " tensor([[0.9818]], device='mps:0'),\n",
              " tensor([[0.9670]], device='mps:0'),\n",
              " tensor([[0.9952]], device='mps:0'),\n",
              " tensor([[0.9972]], device='mps:0'),\n",
              " tensor([[0.9911]], device='mps:0'),\n",
              " tensor([[0.9945]], device='mps:0'),\n",
              " tensor([[0.9767]], device='mps:0'),\n",
              " tensor([[0.9914]], device='mps:0'),\n",
              " tensor([[0.9618]], device='mps:0'),\n",
              " tensor([[0.9651]], device='mps:0'),\n",
              " tensor([[0.9688]], device='mps:0'),\n",
              " tensor([[0.9507]], device='mps:0'),\n",
              " tensor([[0.9749]], device='mps:0'),\n",
              " tensor([[0.9688]], device='mps:0'),\n",
              " tensor([[0.9642]], device='mps:0'),\n",
              " tensor([[0.9750]], device='mps:0'),\n",
              " tensor([[0.9500]], device='mps:0'),\n",
              " tensor([[0.9662]], device='mps:0'),\n",
              " tensor([[0.9580]], device='mps:0'),\n",
              " tensor([[0.9891]], device='mps:0'),\n",
              " tensor([[0.9157]], device='mps:0'),\n",
              " tensor([[0.9955]], device='mps:0'),\n",
              " tensor([[0.9870]], device='mps:0'),\n",
              " tensor([[0.9816]], device='mps:0'),\n",
              " tensor([[0.9476]], device='mps:0'),\n",
              " tensor([[0.9527]], device='mps:0'),\n",
              " tensor([[0.9926]], device='mps:0'),\n",
              " tensor([[0.9959]], device='mps:0'),\n",
              " tensor([[0.9832]], device='mps:0'),\n",
              " tensor([[0.9910]], device='mps:0'),\n",
              " tensor([[0.9587]], device='mps:0'),\n",
              " tensor([[0.9755]], device='mps:0'),\n",
              " tensor([[0.9842]], device='mps:0'),\n",
              " tensor([[0.9383]], device='mps:0'),\n",
              " tensor([[0.9629]], device='mps:0'),\n",
              " tensor([[0.9813]], device='mps:0'),\n",
              " tensor([[0.9814]], device='mps:0'),\n",
              " tensor([[0.9957]], device='mps:0'),\n",
              " tensor([[0.9848]], device='mps:0'),\n",
              " tensor([[0.9970]], device='mps:0'),\n",
              " tensor([[0.9920]], device='mps:0'),\n",
              " tensor([[0.9647]], device='mps:0'),\n",
              " tensor([[0.9788]], device='mps:0'),\n",
              " tensor([[0.8678]], device='mps:0'),\n",
              " tensor([[0.9506]], device='mps:0'),\n",
              " tensor([[0.9451]], device='mps:0'),\n",
              " tensor([[0.9911]], device='mps:0'),\n",
              " tensor([[0.9834]], device='mps:0'),\n",
              " tensor([[0.9781]], device='mps:0'),\n",
              " tensor([[0.9942]], device='mps:0'),\n",
              " tensor([[0.9475]], device='mps:0'),\n",
              " tensor([[0.9832]], device='mps:0'),\n",
              " tensor([[0.9858]], device='mps:0'),\n",
              " tensor([[0.9659]], device='mps:0'),\n",
              " tensor([[0.9621]], device='mps:0'),\n",
              " tensor([[0.9786]], device='mps:0'),\n",
              " tensor([[0.9629]], device='mps:0'),\n",
              " tensor([[0.9903]], device='mps:0'),\n",
              " tensor([[0.8727]], device='mps:0'),\n",
              " tensor([[0.9748]], device='mps:0'),\n",
              " tensor([[0.9813]], device='mps:0'),\n",
              " tensor([[0.9891]], device='mps:0'),\n",
              " tensor([[0.9959]], device='mps:0'),\n",
              " tensor([[0.9860]], device='mps:0'),\n",
              " tensor([[0.9552]], device='mps:0'),\n",
              " tensor([[0.9907]], device='mps:0'),\n",
              " tensor([[0.9597]], device='mps:0'),\n",
              " tensor([[0.9646]], device='mps:0'),\n",
              " tensor([[0.9566]], device='mps:0'),\n",
              " tensor([[0.9915]], device='mps:0'),\n",
              " tensor([[0.9355]], device='mps:0'),\n",
              " tensor([[0.9619]], device='mps:0'),\n",
              " tensor([[0.9936]], device='mps:0'),\n",
              " tensor([[0.9212]], device='mps:0'),\n",
              " tensor([[0.9813]], device='mps:0'),\n",
              " tensor([[0.9938]], device='mps:0'),\n",
              " tensor([[0.9932]], device='mps:0'),\n",
              " tensor([[0.9764]], device='mps:0'),\n",
              " tensor([[0.9660]], device='mps:0'),\n",
              " tensor([[0.9268]], device='mps:0'),\n",
              " tensor([[0.9915]], device='mps:0'),\n",
              " tensor([[0.9049]], device='mps:0'),\n",
              " tensor([[0.9407]], device='mps:0'),\n",
              " tensor([[0.9197]], device='mps:0'),\n",
              " tensor([[0.9431]], device='mps:0'),\n",
              " tensor([[0.9946]], device='mps:0'),\n",
              " tensor([[0.9960]], device='mps:0'),\n",
              " tensor([[0.9816]], device='mps:0'),\n",
              " tensor([[0.9929]], device='mps:0'),\n",
              " tensor([[0.9761]], device='mps:0'),\n",
              " tensor([[0.9687]], device='mps:0'),\n",
              " tensor([[0.9445]], device='mps:0'),\n",
              " tensor([[0.9911]], device='mps:0'),\n",
              " tensor([[0.9844]], device='mps:0'),\n",
              " tensor([[0.9862]], device='mps:0'),\n",
              " tensor([[0.9981]], device='mps:0'),\n",
              " tensor([[0.9943]], device='mps:0'),\n",
              " tensor([[0.9822]], device='mps:0'),\n",
              " tensor([[0.9815]], device='mps:0'),\n",
              " tensor([[0.9441]], device='mps:0'),\n",
              " tensor([[0.9631]], device='mps:0'),\n",
              " tensor([[0.9664]], device='mps:0'),\n",
              " tensor([[0.9192]], device='mps:0'),\n",
              " tensor([[0.9819]], device='mps:0'),\n",
              " tensor([[0.9892]], device='mps:0'),\n",
              " tensor([[0.9763]], device='mps:0'),\n",
              " tensor([[0.9847]], device='mps:0'),\n",
              " tensor([[0.9958]], device='mps:0'),\n",
              " tensor([[0.9962]], device='mps:0'),\n",
              " tensor([[0.9287]], device='mps:0'),\n",
              " tensor([[0.9595]], device='mps:0'),\n",
              " tensor([[0.9825]], device='mps:0'),\n",
              " tensor([[0.9853]], device='mps:0'),\n",
              " tensor([[0.9814]], device='mps:0'),\n",
              " tensor([[0.9465]], device='mps:0'),\n",
              " tensor([[0.9852]], device='mps:0'),\n",
              " tensor([[0.9815]], device='mps:0'),\n",
              " tensor([[0.9948]], device='mps:0'),\n",
              " tensor([[0.9969]], device='mps:0'),\n",
              " tensor([[0.9504]], device='mps:0'),\n",
              " tensor([[0.9840]], device='mps:0'),\n",
              " tensor([[0.9980]], device='mps:0'),\n",
              " tensor([[0.9772]], device='mps:0'),\n",
              " tensor([[0.8529]], device='mps:0'),\n",
              " tensor([[0.9589]], device='mps:0'),\n",
              " tensor([[0.9762]], device='mps:0'),\n",
              " tensor([[0.9658]], device='mps:0'),\n",
              " tensor([[0.9728]], device='mps:0'),\n",
              " tensor([[0.9807]], device='mps:0'),\n",
              " tensor([[0.9515]], device='mps:0'),\n",
              " tensor([[0.9913]], device='mps:0'),\n",
              " tensor([[0.9937]], device='mps:0'),\n",
              " tensor([[0.9381]], device='mps:0'),\n",
              " tensor([[0.9763]], device='mps:0'),\n",
              " tensor([[0.9805]], device='mps:0'),\n",
              " tensor([[0.9621]], device='mps:0'),\n",
              " tensor([[0.9416]], device='mps:0'),\n",
              " tensor([[0.9941]], device='mps:0'),\n",
              " tensor([[0.9834]], device='mps:0'),\n",
              " tensor([[0.9286]], device='mps:0'),\n",
              " tensor([[0.9786]], device='mps:0'),\n",
              " tensor([[0.9937]], device='mps:0'),\n",
              " tensor([[0.9517]], device='mps:0'),\n",
              " tensor([[0.9644]], device='mps:0'),\n",
              " tensor([[0.9496]], device='mps:0'),\n",
              " tensor([[0.9725]], device='mps:0'),\n",
              " tensor([[0.9473]], device='mps:0'),\n",
              " tensor([[0.9780]], device='mps:0'),\n",
              " tensor([[0.9976]], device='mps:0'),\n",
              " tensor([[0.9976]], device='mps:0'),\n",
              " tensor([[0.9934]], device='mps:0'),\n",
              " tensor([[0.9907]], device='mps:0'),\n",
              " tensor([[0.9844]], device='mps:0'),\n",
              " tensor([[0.9864]], device='mps:0'),\n",
              " tensor([[0.9805]], device='mps:0'),\n",
              " tensor([[0.9685]], device='mps:0'),\n",
              " tensor([[0.9754]], device='mps:0'),\n",
              " tensor([[0.9864]], device='mps:0'),\n",
              " tensor([[0.9966]], device='mps:0'),\n",
              " tensor([[0.9948]], device='mps:0'),\n",
              " tensor([[0.9909]], device='mps:0'),\n",
              " tensor([[0.9874]], device='mps:0'),\n",
              " tensor([[0.9447]], device='mps:0'),\n",
              " tensor([[0.8371]], device='mps:0'),\n",
              " tensor([[0.9705]], device='mps:0'),\n",
              " tensor([[0.9394]], device='mps:0'),\n",
              " tensor([[0.9748]], device='mps:0'),\n",
              " tensor([[0.9953]], device='mps:0'),\n",
              " tensor([[0.9928]], device='mps:0'),\n",
              " tensor([[0.9922]], device='mps:0'),\n",
              " tensor([[0.9816]], device='mps:0'),\n",
              " tensor([[0.9530]], device='mps:0'),\n",
              " tensor([[0.9670]], device='mps:0'),\n",
              " tensor([[0.9875]], device='mps:0'),\n",
              " tensor([[0.9619]], device='mps:0'),\n",
              " tensor([[0.9931]], device='mps:0'),\n",
              " tensor([[0.9845]], device='mps:0'),\n",
              " tensor([[0.9746]], device='mps:0'),\n",
              " tensor([[0.9883]], device='mps:0'),\n",
              " tensor([[0.9734]], device='mps:0'),\n",
              " tensor([[0.9790]], device='mps:0'),\n",
              " tensor([[0.9801]], device='mps:0'),\n",
              " tensor([[0.9430]], device='mps:0'),\n",
              " tensor([[0.9932]], device='mps:0'),\n",
              " tensor([[0.9953]], device='mps:0'),\n",
              " tensor([[0.9824]], device='mps:0'),\n",
              " tensor([[0.9954]], device='mps:0'),\n",
              " tensor([[0.9926]], device='mps:0'),\n",
              " tensor([[0.9957]], device='mps:0'),\n",
              " tensor([[0.9922]], device='mps:0'),\n",
              " tensor([[0.9072]], device='mps:0'),\n",
              " tensor([[0.9877]], device='mps:0'),\n",
              " tensor([[0.9822]], device='mps:0'),\n",
              " tensor([[0.8824]], device='mps:0'),\n",
              " tensor([[0.9580]], device='mps:0'),\n",
              " tensor([[0.9820]], device='mps:0'),\n",
              " tensor([[0.9371]], device='mps:0'),\n",
              " tensor([[0.9871]], device='mps:0'),\n",
              " tensor([[0.9615]], device='mps:0'),\n",
              " tensor([[0.9742]], device='mps:0'),\n",
              " tensor([[0.9908]], device='mps:0'),\n",
              " tensor([[0.9847]], device='mps:0'),\n",
              " tensor([[0.9938]], device='mps:0'),\n",
              " tensor([[0.9965]], device='mps:0'),\n",
              " tensor([[0.9873]], device='mps:0'),\n",
              " tensor([[0.9948]], device='mps:0'),\n",
              " tensor([[0.9962]], device='mps:0'),\n",
              " tensor([[0.9465]], device='mps:0'),\n",
              " tensor([[0.9976]], device='mps:0'),\n",
              " tensor([[0.9808]], device='mps:0'),\n",
              " tensor([[0.9950]], device='mps:0'),\n",
              " tensor([[0.9925]], device='mps:0'),\n",
              " tensor([[0.9854]], device='mps:0'),\n",
              " tensor([[0.9909]], device='mps:0'),\n",
              " tensor([[0.9574]], device='mps:0'),\n",
              " tensor([[0.9827]], device='mps:0'),\n",
              " tensor([[0.9851]], device='mps:0'),\n",
              " tensor([[0.9892]], device='mps:0'),\n",
              " tensor([[0.9870]], device='mps:0'),\n",
              " tensor([[0.9876]], device='mps:0'),\n",
              " tensor([[0.9904]], device='mps:0'),\n",
              " tensor([[0.9980]], device='mps:0'),\n",
              " tensor([[0.9927]], device='mps:0'),\n",
              " tensor([[0.9933]], device='mps:0'),\n",
              " tensor([[0.9136]], device='mps:0'),\n",
              " tensor([[0.9530]], device='mps:0'),\n",
              " tensor([[0.8466]], device='mps:0'),\n",
              " tensor([[0.9911]], device='mps:0'),\n",
              " tensor([[0.9443]], device='mps:0'),\n",
              " tensor([[0.9966]], device='mps:0'),\n",
              " tensor([[0.9919]], device='mps:0'),\n",
              " tensor([[0.9966]], device='mps:0'),\n",
              " tensor([[0.9957]], device='mps:0'),\n",
              " tensor([[0.9230]], device='mps:0'),\n",
              " tensor([[0.9814]], device='mps:0'),\n",
              " tensor([[0.9943]], device='mps:0')]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preprocess = torchvision.transforms.Compose([\n",
        "                torchvision.transforms.Resize(256),\n",
        "                torchvision.transforms.CenterCrop(224),\n",
        "                torchvision.transforms.ToTensor(),\n",
        "                torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
        "                                                 std=[0.229, 0.224, 0.225]),\n",
        "            ])\n",
        "\n",
        "pred_list = []\n",
        "img_pred_list = []\n",
        "for k in img_de_moi :\n",
        "  with torch.no_grad():\n",
        "    img = Image.open(k)\n",
        "    img_t = preprocess(img)\n",
        "    img_gpu = img_t.to(device)\n",
        "    pred = resNet50_model(img_gpu.unsqueeze(0))\n",
        "    img_pred = torch.round(pred)\n",
        "    img_pred_list.append(img_pred)\n",
        "    pred_list += pred\n",
        "\n",
        "img_pred_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQfnAE50FeU1"
      },
      "outputs": [],
      "source": [
        "img_test = dataset_val[5][0].unsqueeze(0).to(device)\n",
        "a = torchvision.transforms.ToPILImage()(img_test.squeeze(0))\n",
        "a.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4dzqv0CHPUj"
      },
      "outputs": [],
      "source": [
        "torch.save(res50, data_path + '/res50_face_detection_2.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LLavxPbv9cW"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "with open('losses.pickle', 'rb') as pkl:\n",
        "    losses = pickle.load(pkl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "ldxbH1U1wGgn",
        "outputId": "3ff057c0-59bd-48a5-9462-d9d9ae96645d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f02a07c70d0>]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_loss = losses['train_loss']\n",
        "valid_loss = losses['valid_loss']\n",
        "\n",
        "train_loss_a = np.array(train_loss)\n",
        "valid_loss_a = np.array(valid_loss)\n",
        "\n",
        "plt.plot(train_loss_a)\n",
        "plt.plot(valid_loss_a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyP5OBZtGk6Y",
        "outputId": "f6da79d1-d855-4276-9e29-f44bafeb55b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([7.26754189e-01, 1.27096283e+00, 1.72886929e+00, 1.91742384e+00,\n",
              "       2.06040400e+00, 2.19214158e+00, 2.22320805e+00, 2.24446922e+00,\n",
              "       2.26210658e+00, 2.27291502e+00, 2.28503628e+00, 2.32956765e+00,\n",
              "       2.33472416e+00, 2.34417710e+00, 2.35653077e+00, 2.37167861e+00,\n",
              "       2.37641066e+00, 2.38186004e+00, 2.38256879e+00, 2.39096806e+00,\n",
              "       2.39144261e+00, 2.39199617e+00, 2.39278914e+00, 2.39347116e+00,\n",
              "       2.39384132e+00, 2.39415927e+00, 2.39570596e+00, 2.39635188e+00,\n",
              "       2.39771858e+00, 2.39805939e+00, 2.39903542e+00, 2.40264012e+00,\n",
              "       2.40316140e+00, 2.40353961e+00, 2.40833454e+00, 2.40895863e+00,\n",
              "       2.40954224e+00, 2.41138165e+00, 2.41284637e+00, 2.41322967e+00,\n",
              "       2.41341100e+00, 2.41832886e+00, 2.41856607e+00, 2.41924852e+00,\n",
              "       2.42359686e+00, 2.42410438e+00, 2.42441930e+00, 2.42464649e+00,\n",
              "       2.42509494e+00, 2.42522560e+00, 2.42538189e+00, 2.42555796e+00,\n",
              "       2.42563661e+00, 2.42585543e+00, 1.56572997e-03, 1.79192632e-03,\n",
              "       2.35735990e-03, 2.52078021e-03, 2.76488571e-03, 3.77730587e-03,\n",
              "       3.92060755e-03, 4.05567369e-03, 4.74596201e-03, 4.91304186e-03,\n",
              "       5.68140516e-03, 6.13943793e-03, 6.57174771e-03, 6.83921389e-03,\n",
              "       7.15044240e-03, 7.33273673e-03, 7.51084488e-03, 7.63663409e-03,\n",
              "       7.85630252e-03, 8.43042313e-03, 8.59985130e-03, 8.78570213e-03,\n",
              "       8.99112943e-03, 9.46640232e-03, 9.69681608e-03, 9.86589631e-03,\n",
              "       1.01890512e-02, 1.02656661e-02, 1.06211931e-02, 1.12553679e-02,\n",
              "       1.13344501e-02, 1.15228208e-02, 1.15926068e-02, 1.21648574e-02,\n",
              "       1.22144438e-02, 1.24961934e-02, 1.26285612e-02, 1.27784898e-02,\n",
              "       1.32063446e-02, 1.33129001e-02, 1.40364524e-02, 1.41934479e-02,\n",
              "       1.44246192e-02, 1.46289130e-02, 1.47392533e-02, 1.51235947e-02,\n",
              "       1.52639572e-02, 1.53837179e-02, 1.56798106e-02, 1.58920343e-02,\n",
              "       1.62169517e-02, 1.65967018e-02, 1.75555941e-02, 1.75755927e-02])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_loss_a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "48a4d05996034510842c3fb754cbaae4",
            "0c986a5fcd4c4e648a5d172416743f1d",
            "dc6a6acf6d784383a2ee14e946b3e9df",
            "9134a56d65e44920b934415282059717",
            "726fab65e7824292b0f2c26c40e60bf9",
            "c4268414c8e0432eaabc07a5e1388cb1",
            "454043362df747e38847b07bcb00f530",
            "959072464d8543a0915a238b779982de",
            "053e107f70af40dfbd4a8890567a58b5",
            "d3f8672711874208b71bc31e063e6fec",
            "0c7d2138828d49289eedd4b839632aad"
          ]
        },
        "id": "1WIo8lk-KXog",
        "outputId": "fb0f5149-d686-4545-95d7-2d7da87b16c2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48a4d05996034510842c3fb754cbaae4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "res18 = torchvision.models.resnet18(pretrained = True, progress = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sV4q2kbyBrKh",
        "outputId": "f0d888bd-ff37-4fa3-e207-897335ac9d6c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0YnTwxqBuTI",
        "outputId": "b047c45b-4d57-4ce9-d002-b4beeab97c1e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnktpPp5B0uf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPWinBN4bqoFkAA/XEqFXIk",
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/ThOpaque/HomeMade_FaceID/blob/main/FaceDetection.ipynb",
      "name": "Face_detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "bfc2e043f4a41bbce066f7921047bdcfe8769546c7198e4df6482fd90de274f1"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "053e107f70af40dfbd4a8890567a58b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0c7d2138828d49289eedd4b839632aad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c986a5fcd4c4e648a5d172416743f1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4268414c8e0432eaabc07a5e1388cb1",
            "placeholder": "​",
            "style": "IPY_MODEL_454043362df747e38847b07bcb00f530",
            "value": "100%"
          }
        },
        "0fc7e5f1d6274e0da948779e948627e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c7a8660130e40bbab6de68e755ca128": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "32e2a52a05e24d60b7548433155e72ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_505db89d72b34a34971291ccfaf0b3ff",
              "IPY_MODEL_4c553a6a3c224c07b42016e31ac7285d",
              "IPY_MODEL_c58a474359344e4e9944c2115121cf7d"
            ],
            "layout": "IPY_MODEL_4f205a6e23cd4a12947ea64ef1dc986e"
          }
        },
        "439e24adee154320b79b7cac83c53a30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "454043362df747e38847b07bcb00f530": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48a4d05996034510842c3fb754cbaae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c986a5fcd4c4e648a5d172416743f1d",
              "IPY_MODEL_dc6a6acf6d784383a2ee14e946b3e9df",
              "IPY_MODEL_9134a56d65e44920b934415282059717"
            ],
            "layout": "IPY_MODEL_726fab65e7824292b0f2c26c40e60bf9"
          }
        },
        "4c553a6a3c224c07b42016e31ac7285d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac34c26b2cdf4c1493da71ed7e5410f0",
            "max": 102530333,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c7a8660130e40bbab6de68e755ca128",
            "value": 102530333
          }
        },
        "4f205a6e23cd4a12947ea64ef1dc986e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "505db89d72b34a34971291ccfaf0b3ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa83ab9de4374921853df19db53dded8",
            "placeholder": "​",
            "style": "IPY_MODEL_439e24adee154320b79b7cac83c53a30",
            "value": "100%"
          }
        },
        "726fab65e7824292b0f2c26c40e60bf9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9134a56d65e44920b934415282059717": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3f8672711874208b71bc31e063e6fec",
            "placeholder": "​",
            "style": "IPY_MODEL_0c7d2138828d49289eedd4b839632aad",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 139MB/s]"
          }
        },
        "959072464d8543a0915a238b779982de": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac34c26b2cdf4c1493da71ed7e5410f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4268414c8e0432eaabc07a5e1388cb1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c58a474359344e4e9944c2115121cf7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fc7e5f1d6274e0da948779e948627e3",
            "placeholder": "​",
            "style": "IPY_MODEL_c913ab7aad7e49a79fde819c99acd1a4",
            "value": " 97.8M/97.8M [00:01&lt;00:00, 135MB/s]"
          }
        },
        "c913ab7aad7e49a79fde819c99acd1a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3f8672711874208b71bc31e063e6fec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc6a6acf6d784383a2ee14e946b3e9df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_959072464d8543a0915a238b779982de",
            "max": 46830571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_053e107f70af40dfbd4a8890567a58b5",
            "value": 46830571
          }
        },
        "fa83ab9de4374921853df19db53dded8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
